Hello this is a test. Can my 
program 
pass correct data?

Who knows only time will tell.

Figure 1.5 This is a model showing the number of transistors on a chipset and the year of production (Wikipedia, Transistor Count).
	
	During this period of computer development, computers have had a hand in helping develop huge scientific breakthroughs. Every scientific field has employed computers as a tool to further scientific discovery. However, what are the limits to classical computation? Can computers act as more than just a tool and generate new knowledge? In recent years, due to the rapid evolution of transistor technology, computers are now more powerful than ever before. A particular field in computer science that is gaining more popularity in mainstream media is machine learning, or as it's more colloquially known as, artificial intelligence.
	This field specifically deals with the development of machines that can analyze data and automatically build a model from that data. This is achieved from using algorithms that iteratively learn from data and allow computers to find patterns and insights without being explicitly programmed (SAS). Though there are many different machine learning algorithms, they all follow the same basic formula. The first stage is the user defined model. This is where software engineers give an initial condition and define what they believe a potential original model of the particular set of data to be. The second stage is when this initial model is applied to another data set. Any discrepancies are built into the model and the model is revised. This is called the learning stage. This whole process repeats many times over and over, and each time the model changes to a more and more accurate version of itself. While this methodology is good for refining a particular model, or giving the computer the ability to recognize patterns that we already see, it isn't conducive to raw creative power that is necessary to generate new knowledge. This method of machine learning is referred to as supervised learning. Supervised learning is where machines are provided with "training" data that comes in the form of human input. 
	As a result of this advancement in technology, questions about machine's creativity and ability to generate new knowledge have developed. An interesting question is whether or not a computer, through the process of deep learning, can develop new knowledge for humankind. To answer this question, the term new knowledge has to be defined. New knowledge can be loosely defined as an observation about an element of an object that goes beyond existing human understanding and framework. For example, the discovery of general relativity by Albert Einstein pushed the boundaries of the existing human framework of physics and as a result a new model of understanding the physical world has developed.
	Historically, new knowledge has been developed by observing some previously unobservable or undetected feature of a problem. "If a solvable problem is currently unsolved, then something important of a solution is most likely being overlooked" (McCaffrey). This suggests that in order to provide a solution to a currently solution-less but solvable problem, computers need to be able to observe and detect aspects of the solution that are currently undetectable or unobserved. Many times, in the past, computers have assisted us in detecting and observing new features that lead to a previously unknown solution. However, the computer generation of a completely novel theorem has yet to occur. 
		